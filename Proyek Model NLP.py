# -*- coding: utf-8 -*-
"""ProjekNLP_Muhammad Faqih Hakim.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DuJ0w_JyeScScNNEQQsGQIf0sJIxrsD_

**Proyek Pertama : Membuat Model NLP dengan TensorFlow**

Berikut kriteria submission yang harus Anda penuhi:

* Dataset yang akan dipakai bebas, namun minimal memiliki 1000 sampel.

* Harus menggunakan LSTM dalam arsitektur model.

* Harus menggunakan model sequential.

* Validation set sebesar 20% dari total dataset.

* Harus menggunakan Embedding.

* Harus menggunakan fungsi tokenizer.

* Akurasi dari model minimal 75% pada train set dan validation set.

Data Diri:


Nama: Muhammad Faqih Hakim

Dataset yang akan dipakai bebas, namun minimal memiliki 1000 sampel.

Import Library yang dibutuhkan
"""

import keras
import nltk
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split
from keras.preprocessing.text import Tokenizer
from sklearn.preprocessing import LabelEncoder
from keras.preprocessing.sequence import pad_sequences
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk import punkt
import string

nltk.download('punkt')
nltk.download('stopwords')

"""dataset bisa di dapat dari https://www.kaggle.com/datasets/krystalliu152/imbd-movie-reviewnpl"""

df = pd.read_csv('/content/Review.csv')
df

"""Ubah Nilai dari sentiment yang berisi positive dan negative menjadi 1 dan 0(binary classfication text)"""

label_encoder = LabelEncoder()
df['sentiment'] = label_encoder.fit_transform(df['sentiment'])

df['sentiment'].dtype

df['sentiment'].astype(bool)

"""Preprocessing Text"""

def preprocess_text(text):
    text = text.lower()
    text = ''.join([char for char in text if char not in string.punctuation])
    word_tokens = word_tokenize(text)
    stop_words = set(stopwords.words('english'))
    filtered_sentence = [w for w in word_tokens if not w in stop_words]
    return ' '.join(filtered_sentence)

df['review'] = df['review'].apply(preprocess_text)
df

"""menentukan Label"""

review = df['review'].values
label = df['sentiment'].values

"""Validation set sebesar 20% dari total dataset."""

review_train, review_val, label_train, label_val = train_test_split(review, label, test_size=0.2)

"""Harus menggunakan fungsi tokenizer"""

tokenizer = Tokenizer(num_words=10000, oov_token='x')
tokenizer.fit_on_texts(review_train)

sequences_train = tokenizer.texts_to_sequences(review_train)
sequences_val = tokenizer.texts_to_sequences(review_val)

padded_train = pad_sequences(sequences_train, maxlen=20, padding='post')
padded_val = pad_sequences(sequences_val, maxlen=20, padding='post')

"""Implementasi Fungsi Callback"""

class myCallback(keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if (logs.get('val_accuracy') >= 0.75 and logs.get('accuracy') >= 0.8):
            print("\nPelatihan harus dihentikan karena Sudah mencapai target yang diinginkan")
            self.model.stop_training = True

callbacks = myCallback()

"""Buat Model Sequential, dengan mengimplementasikan Layer Embedding dan TLSM

disini juga saya menggunakan layer Dropout untuk mengatasi overfitting
"""

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=10000, output_dim=32, input_length=20),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.LSTM(128, return_sequences=True),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

"""Compile Model"""

model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

"""Latih Model"""

history = model.fit(padded_train, label_train,
                    epochs=20,
                    batch_size=32,
                    validation_data=(padded_val, label_val),
                    callbacks=[callbacks])

"""Plot Loss model"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train'], loc='upper right')
plt.show()

"""Plot Akurasi"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train'], loc='lower right')
plt.show()

